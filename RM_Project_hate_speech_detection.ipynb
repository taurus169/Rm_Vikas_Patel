{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "RM_PROJECT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXI7Fq0W4A3H"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ZV71_2m54A3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ebc40f-9830-466d-bff6-80264a811d84"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# Here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# For data preprocessing\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#NLP tools\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#train split and fit models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#model selection\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSYogx6s4A3j"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "-AR7Mega4A3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "21fe5675-c1e2-401a-8255-0974596e30b1"
      },
      "source": [
        "dataset = pd.read_csv('/content/labeled_data.csv')\n",
        "dataset.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  ...  class                                              tweet\n",
              "0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1           1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2           2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3           3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4           4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vs8TgBgV4A36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08243b36-9faf-441d-ea04-82b0939d2443"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24783 entries, 0 to 24782\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Unnamed: 0          24783 non-null  int64 \n",
            " 1   count               24783 non-null  int64 \n",
            " 2   hate_speech         24783 non-null  int64 \n",
            " 3   offensive_language  24783 non-null  int64 \n",
            " 4   neither             24783 non-null  int64 \n",
            " 5   class               24783 non-null  int64 \n",
            " 6   tweet               24783 non-null  object\n",
            "dtypes: int64(6), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nd1w1ZAC4A4I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cdf3fb1a-5346-476e-8409-ebd0a5d4d00b"
      },
      "source": [
        "dataset.describe().T"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>12681.192027</td>\n",
              "      <td>7299.553863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6372.5</td>\n",
              "      <td>12703.0</td>\n",
              "      <td>18995.5</td>\n",
              "      <td>25296.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>3.243473</td>\n",
              "      <td>0.883060</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hate_speech</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>0.280515</td>\n",
              "      <td>0.631851</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>offensive_language</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>2.413711</td>\n",
              "      <td>1.399459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neither</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>0.549247</td>\n",
              "      <td>1.113299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>24783.0</td>\n",
              "      <td>1.110277</td>\n",
              "      <td>0.462089</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      count          mean  ...      75%      max\n",
              "Unnamed: 0          24783.0  12681.192027  ...  18995.5  25296.0\n",
              "count               24783.0      3.243473  ...      3.0      9.0\n",
              "hate_speech         24783.0      0.280515  ...      0.0      7.0\n",
              "offensive_language  24783.0      2.413711  ...      3.0      9.0\n",
              "neither             24783.0      0.549247  ...      0.0      9.0\n",
              "class               24783.0      1.110277  ...      1.0      2.0\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AeI8Qvh24A4X"
      },
      "source": [
        "dt_trasformed = dataset[['class', 'tweet']]\n",
        "y = dt_trasformed.iloc[:, :-1].values"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7JKq33-4A4o"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MYm001G94A4x"
      },
      "source": [
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "y = np.array(ct.fit_transform(y))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JkcoeYy04A4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014102fb-aadb-47bb-d836-bf0b6b05c768"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdgwj3eg4A5N"
      },
      "source": [
        "This data has been split into two variables that will be used to fit hate speech and offensive speech models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_pu0j1wV4A5R"
      },
      "source": [
        "y_df = pd.DataFrame(y)\n",
        "y_hate = np.array(y_df[0])\n",
        "y_offensive = np.array(y_df[1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0pvkOAoV4A5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac47fe5-46a4-406e-9b21-98deb50c28be"
      },
      "source": [
        "print(y_hate)\n",
        "print(y_offensive)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 1. 1. ... 1. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp4dM1uc4A5y"
      },
      "source": [
        "## Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O3WTpbBk4A52"
      },
      "source": [
        "corpus = []\n",
        "for i in range(0, 24783):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dt_trasformed['tweet'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LyjT0GeO4A6G"
      },
      "source": [
        "cv = CountVectorizer(max_features = 2000)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeyGB6uf4A6b"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w8X27tlK4A6d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_hate, test_size = 0.30, random_state = 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrip21SO4A6p"
      },
      "source": [
        "## Finding the best models to predict hate speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8gCnW1T4A6r"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "shBGTnf74A6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e64d84f-e1e1-4b24-c97f-56c187bb9274"
      },
      "source": [
        "classifier_np = GaussianNB()\n",
        "classifier_np.fit(X_train, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kq4N8Yu4A7K"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "liJRh4mS4A7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8962f0b-60e6-4ce3-dea8-f87b4977d422"
      },
      "source": [
        "classifier_lr = LogisticRegression(random_state = 0)\n",
        "classifier_lr.fit(X_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhbW2mMW4A7f"
      },
      "source": [
        "SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "huXdBXwc4A7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27de6dcc-bd17-4048-d653-10b65c9ccb06"
      },
      "source": [
        "classifier_svm = svm.SVC()\n",
        "classifier_svm.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLPQDu1Q4A7s"
      },
      "source": [
        "# Making the Confusion Matrix for each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8su41ZE14A7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a48d0f-14c1-4f9e-e11c-0462e20d80fe"
      },
      "source": [
        "#Naive Bayes\n",
        "y_pred_np = classifier_np.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_np)\n",
        "print(cm)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3289 3719]\n",
            " [ 168  259]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cx8OY7qB4A7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6a1d65-7da4-4081-85f4-c14e54ab9b4e"
      },
      "source": [
        "#SVM\n",
        "y_pred_svm = classifier_svm.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_svm)\n",
        "print(cm)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6964   44]\n",
            " [ 372   55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Wkj0f3f4A8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b362c5-3bb5-4c02-91dd-67715c19b14c"
      },
      "source": [
        "#Logistic Regression\n",
        "y_pred_lr=classifier_lr.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "print(cm)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6911   97]\n",
            " [ 347   80]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R9Jy8JO44A8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8103e27d-c785-4cc2-f18e-315d5fb977c7"
      },
      "source": [
        "svm_score = accuracy_score(y_test, y_pred_svm)\n",
        "lr_score = accuracy_score(y_test, y_pred_lr)\n",
        "np_score = accuracy_score(y_test, y_pred_np)\n",
        "\n",
        "print('Support Vector Machine Accuracy: ', str(svm_score))\n",
        "print('Logistic Regression Accuracy: ',str(lr_score))\n",
        "print('Naive Bayes Accuracy: ', str(np_score))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Support Vector Machine Accuracy:  0.9440484196368527\n",
            "Logistic Regression Accuracy:  0.9402824478816408\n",
            "Naive Bayes Accuracy:  0.4772024209818426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81nDFw__4A8c"
      },
      "source": [
        "*So* Based on this dataset, Support Vector Machine appears to be a superior predictor of hate speech. It's worth noting that Logistic Regression produced excellent results as well. This Dataset appears to be an artificial intelligence product used to classify hate and abusive speech."
      ]
    }
  ]
}